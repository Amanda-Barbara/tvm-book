{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D 卷积\n",
    "\n",
    "约定：\n",
    "\n",
    "1. 尽量使用 NumPy 低级接口与 TIR 进行对比。\n",
    "2. NumPy 高级接口版本计算结果作为基准。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/pc/data/4tb/lxw/home/lxw/tvm-book/doc/tutorials\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import set_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm.script import tir as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 NCHW 布局的卷积的数学定义：\n",
    "\n",
    "$$\n",
    "\\text{Conv}[b, k, i, j] =\n",
    "    \\sum_{d_i, d_j, q} A[b, q, \\text{strides} * i + d_i, \\text{strides} * j + d_j] * W[k, q, d_i, d_j],\n",
    "$$\n",
    "\n",
    "其中，$A$ 是输入张量，$W$ 是权重张量，$b$ 是批次索引，$k$ 是输出通道，$i$ 和 $j$ 是图像高度和宽度的索引，$d_i$ 和 $d_j$ 是权重的索引，$q$ 是输入通道，`strides` 是过滤器窗口的步幅。\n",
    "\n",
    "下面考虑简单的情况：`stride=1, padding=0`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, CI, H, W, CO, K = 1, 1, 8, 8, 2, 3\n",
    "OUT_H, OUT_W = H - K + 1, W - K + 1\n",
    "data = np.arange(N*CI*H*W).reshape(N, CI, H, W)\n",
    "weight = np.arange(CO*CI*K*K).reshape(CO, CI, K, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch` 版本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data_torch = torch.Tensor(data)\n",
    "weight_torch = torch.Tensor(weight)\n",
    "conv_torch = torch.nn.functional.conv2d(data_torch, weight_torch)\n",
    "conv_torch = conv_torch.numpy().astype(np.int64)\n",
    "conv_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TVM 版本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyConv:\n",
    "  @T.prim_func\n",
    "  def conv(A: T.Buffer[(1, 1, 8, 8), \"int64\"], # 1,1,8,8\n",
    "          B: T.Buffer[(2, 1, 3, 3), \"int64\"], # 2,1,3,3\n",
    "          C: T.Buffer[(1, 2, 6, 6), \"int64\"]): # 1,2,6,6\n",
    "    T.func_attr({\"global_symbol\": \"conv\", \"tir.noalias\": True})\n",
    "    for n, c, h, w, i, k1, k2 in T.grid(N, CO, OUT_H, OUT_W, CI, K, K):\n",
    "      with T.block(\"C\"):\n",
    "        vn = T.axis.spatial(1, n)\n",
    "        vc = T.axis.spatial(2, c)\n",
    "        vh = T.axis.spatial(6, h)\n",
    "        vw = T.axis.spatial(6, w)\n",
    "        vi = T.axis.spatial(1, i)\n",
    "        vk1 = T.axis.reduce(3, k1)\n",
    "        vk2 = T.axis.reduce(3, k2)\n",
    "        with T.init():\n",
    "          C[vn, vc, vh, vw] = T.int64(0)\n",
    "        C[vn, vc, vh, vw] = C[vn, vc, vh, vw] + A[vn, vi, vh + vk1, vw + vk2] * B[vc, vi, vk1, vk2]\n",
    "\n",
    "\n",
    "rt_lib = tvm.build(MyConv, target=\"llvm\")\n",
    "data_tvm = tvm.nd.array(data)\n",
    "weight_tvm = tvm.nd.array(weight)\n",
    "conv_tvm = tvm.nd.array(np.empty((N, CO, OUT_H, OUT_W), dtype=np.int64))\n",
    "rt_lib[\"conv\"](data_tvm, weight_tvm, conv_tvm)\n",
    "np.testing.assert_allclose(conv_tvm.numpy(), conv_torch, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再考虑有 padding 和 stride 的卷积："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = te.placeholder((2, 3, 4))\n",
    "B = pad2d(A, 1, 1)\n",
    "s = te.create_schedule(B.op)\n",
    "mod = tvm.build(s, [A, B])\n",
    "\n",
    "a = tvm.nd.array(np.ones((2,3,4), dtype='float32'))\n",
    "b = tvm.nd.array(np.empty((2,5,6), dtype='float32'))\n",
    "mod(a, b)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tvmx': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e579259ee6098e2b9319de590d145b4b096774fe457bdf04260e3ba5c171e887"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
