{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试 ImageNet 分类精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 16:03:37.608487: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-21 16:03:37.815194: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-21 16:03:37.817549: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-21 16:03:40.697419: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tasks/models/research/slim\n",
      "WARNING:tensorflow:From /tmp/ipykernel_2381233/575585929.py:50: The name tf.keras.utils.track_tf1_style_variables is deprecated. Please use tf.compat.v1.keras.utils.track_tf1_style_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "try:\n",
    "    tf1 = tf.compat.v1\n",
    "except (ImportError, AttributeError):\n",
    "    tf1 = tf\n",
    "%cd /media/pc/data/lxw/ai/tasks/models/research/slim\n",
    "from nets import resnet_v2\n",
    "import tf_slim as slim\n",
    "import numpy as np\n",
    "from tvm_book.metric.classification import Accuracy, TopKAccuracy\n",
    "from tvm_book.data.classification import ImageFolderDataset\n",
    "from tvm_book.data.imagenet.classification import ImageNet1kAttr\n",
    "\n",
    "# @tf.function\n",
    "def preprocessing(\n",
    "    image,\n",
    "    use_grayscale=False,\n",
    "    central_fraction=0.875,\n",
    "    central_crop=True,\n",
    "    height=224,\n",
    "    width=224,\n",
    "    mean: tuple[float, ...] = (0.485, 0.456, 0.406),\n",
    "    std: tuple[float, ...] = (0.229, 0.224, 0.225)\n",
    "):\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    if image.dtype != tf.float32:\n",
    "        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    if use_grayscale:\n",
    "        image = tf.image.rgb_to_grayscale(image)\n",
    "    if central_crop and central_fraction:\n",
    "        image = tf.image.central_crop(image, central_fraction=central_fraction)\n",
    "    if height and width:\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        image = tf.image.resize(image, [height, width],\n",
    "                                method='bilinear',\n",
    "                                preserve_aspect_ratio=False,\n",
    "                                antialias=False)\n",
    "        image = tf.squeeze(image, [0])\n",
    "    image = tf.subtract(image, tf.constant(mean, dtype=tf.float32))\n",
    "    image = tf.divide(image, tf.constant(std, dtype=tf.float32))\n",
    "    return image\n",
    "\n",
    "class ResnetV2_50(tf.keras.Model):\n",
    "    def __init__(self, trainable=False, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.trainable = trainable\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec([1, 3, 299, 299], \n",
    "                                                 tf.float32, name=\"data\")])\n",
    "    @tf1.keras.utils.track_tf1_style_variables\n",
    "    def call(self, x):\n",
    "        # x = tf.convert_to_tensor(x, tf.float32) # 确保输入是 tensor\n",
    "        x = tf.transpose(x, perm=(0, 2, 3, 1)) # NCHW -> NHWC\n",
    "        with slim.arg_scope(resnet_v2.resnet_arg_scope()):\n",
    "            logits, end_points = resnet_v2.resnet_v2_50(\n",
    "                x, \n",
    "                num_classes=1001,\n",
    "                global_pool=True,\n",
    "                is_training=self.trainable,\n",
    "                scope=\"resnet_v2_50\"\n",
    "            )\n",
    "        del end_points\n",
    "        return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 16:03:52.183666: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer.py:2212: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer.py:1345: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`layer.updates` will be removed in a future version. '\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/lib/python3.10/site-packages/keras/legacy_tf_layers/base.py:627: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  self.updates, tf.compat.v1.GraphKeys.UPDATE_OPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/pc/data/tmp/cache/conda/envs/tvmz/lib/python3.10/site-packages/tensorflow/python/checkpoint/checkpoint.py:1426: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.\n"
     ]
    }
   ],
   "source": [
    "model = ResnetV2_50()\n",
    "model(tf.ones(shape=(1, 3, 299, 299), dtype=tf.float32))\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt_path = \"/media/pc/data/board/arria10/lxw/tests/npu_user_demos/models/resnet50_v2_tf/weight/resnet_v2_50.ckpt\"\n",
    "ckpt.restore(ckpt_path) # 更新模型参数\n",
    "root = \"/media/pc/data/lxw/home/data/datasets/ILSVRC/val\"\n",
    "valset = ImageFolderDataset(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Accuracy: {'Accuracy': 0.0} TopKAccuracy: {'top_5_accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1003it [01:04, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001: Accuracy: {'Accuracy': 0.8861138861138861} TopKAccuracy: {'top_5_accuracy': 0.967032967032967}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2003it [02:08, 15.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001: Accuracy: {'Accuracy': 0.8275862068965517} TopKAccuracy: {'top_5_accuracy': 0.9545227386306847}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3003it [03:16, 14.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3001: Accuracy: {'Accuracy': 0.7944018660446518} TopKAccuracy: {'top_5_accuracy': 0.9456847717427525}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4003it [04:24, 14.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4001: Accuracy: {'Accuracy': 0.773056735816046} TopKAccuracy: {'top_5_accuracy': 0.9380154961259685}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5003it [05:40, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001: Accuracy: {'Accuracy': 0.7966406718656269} TopKAccuracy: {'top_5_accuracy': 0.9444111177764447}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6002it [06:54, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6001: Accuracy: {'Accuracy': 0.7998666888851858} TopKAccuracy: {'top_5_accuracy': 0.9418430261623063}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7002it [08:07, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7001: Accuracy: {'Accuracy': 0.8070275674903585} TopKAccuracy: {'top_5_accuracy': 0.9448650192829596}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8003it [09:18, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8001: Accuracy: {'Accuracy': 0.8115235595550556} TopKAccuracy: {'top_5_accuracy': 0.9472565929258843}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9003it [10:35, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9001: Accuracy: {'Accuracy': 0.8029107876902566} TopKAccuracy: {'top_5_accuracy': 0.9463392956338185}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9705it [11:28, 12.89it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "metric = Accuracy()\n",
    "top5_metric = TopKAccuracy(top_k=5)\n",
    "imagenet1k_attr = ImageNet1kAttr()\n",
    "for k, (image, label_id) in tqdm(enumerate(valset)):\n",
    "    processed_image = preprocessing(\n",
    "        image,\n",
    "        use_grayscale=False,\n",
    "        central_fraction=0.875,\n",
    "        central_crop=True,\n",
    "        height=299,\n",
    "        width=299,\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(1, 1, 1)\n",
    "    )\n",
    "    np_processed_images = np.expand_dims(processed_image.numpy(), axis=0)\n",
    "    np_processed_images = np_processed_images.transpose(0, 3, 1, 2)\n",
    "    outputs = model(np_processed_images)\n",
    "    outputs = outputs.numpy()\n",
    "    metric.update(labels=np.array([label_id+1]), preds=outputs)\n",
    "    top5_metric.update(labels=np.array([label_id+1]), preds=outputs)\n",
    "    if k%1000==0:\n",
    "        print(f\"{k+1}: {metric} {top5_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{metric} {top5_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
