{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 翻译为 ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/tutorials/frontend\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from utils.onnx_utils import (\n",
    "    get_input_data_shape_dict,\n",
    "    make_constant_node, get_onnxruntime_output,\n",
    "    get_tvm_output, get_tvm_output_with_vm,\n",
    "    verify_with_ort, verify_with_ort_with_inputs,\n",
    "    quantize_and_verify_with_ort\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch 算子测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `unsqueeze_constant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import onnx\n",
    "from tvm import relay\n",
    "import tempfile\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input_):\n",
    "        return input_.view(input_.size(0), -1)\n",
    "\n",
    "with tempfile.NamedTemporaryFile() as f:\n",
    "    file_name = f.name\n",
    "    input_size = (1, 16, 32, 32)\n",
    "    dummy_input = torch.randn(*input_size)\n",
    "    layer = nn.Sequential(nn.Flatten(), nn.Linear(16 * 32 * 32, 64))\n",
    "    torch.onnx.export(layer, dummy_input, file_name, export_params=True)\n",
    "\n",
    "    onnx_model = onnx.load(file_name)\n",
    "    relay.frontend.from_onnx(onnx_model, {\"onnx::Flatten_0\": input_size})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `embedding_bag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_aten(target, dev):\n",
    "    \"\"\"test_aten\"\"\"\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    def _convert_to_onnx(model, inputs):\n",
    "        file_name = \"aten_model.onnx\"\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            inputs,\n",
    "            file_name,\n",
    "            export_params=True,\n",
    "            verbose=False,\n",
    "            opset_version=10,\n",
    "            operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN,\n",
    "        )\n",
    "        onnx_model = onnx.load(file_name)\n",
    "        return onnx_model\n",
    "\n",
    "    def verify_embedding_bag(num_embedding, embedding_dim, data_shape, num_bags=None):\n",
    "        dummy_data = torch.randint(0, num_embedding - 1, data_shape)\n",
    "        tvm_inputs = [dummy_data.numpy()]\n",
    "        model = torch.nn.EmbeddingBag(num_embedding, embedding_dim)\n",
    "        onnx_model = _convert_to_onnx(model, dummy_data)\n",
    "        torch_out = model(dummy_data)\n",
    "        tvm_out = get_tvm_output_with_vm(\n",
    "            onnx_model,\n",
    "            tvm_inputs,\n",
    "            freeze_params=True,\n",
    "            target=target,\n",
    "            dev=dev,\n",
    "        )\n",
    "        np.testing.assert_allclose(torch_out.numpy(), tvm_out, atol=5e-7)\n",
    "\n",
    "    verify_embedding_bag(10, 3, [2, 10])\n",
    "    verify_embedding_bag(32, 2, [3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Operator numel is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_aten(\u001b[39m\"\u001b[39;49m\u001b[39mllvm\u001b[39;49m\u001b[39m\"\u001b[39;49m, tvm\u001b[39m.\u001b[39;49mcpu())\n",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m, in \u001b[0;36mtest_aten\u001b[0;34m(target, dev)\u001b[0m\n\u001b[1;32m     25\u001b[0m     tvm_out \u001b[39m=\u001b[39m get_tvm_output_with_vm(\n\u001b[1;32m     26\u001b[0m         onnx_model,\n\u001b[1;32m     27\u001b[0m         tvm_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m         dev\u001b[39m=\u001b[39mdev,\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     32\u001b[0m     np\u001b[39m.\u001b[39mtesting\u001b[39m.\u001b[39massert_allclose(torch_out\u001b[39m.\u001b[39mnumpy(), tvm_out, atol\u001b[39m=\u001b[39m\u001b[39m5e-7\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m verify_embedding_bag(\u001b[39m10\u001b[39;49m, \u001b[39m3\u001b[39;49m, [\u001b[39m2\u001b[39;49m, \u001b[39m10\u001b[39;49m])\n\u001b[1;32m     35\u001b[0m verify_embedding_bag(\u001b[39m32\u001b[39m, \u001b[39m2\u001b[39m, [\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m])\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mtest_aten.<locals>.verify_embedding_bag\u001b[0;34m(num_embedding, embedding_dim, data_shape, num_bags)\u001b[0m\n\u001b[1;32m     23\u001b[0m onnx_model \u001b[39m=\u001b[39m _convert_to_onnx(model, dummy_data)\n\u001b[1;32m     24\u001b[0m torch_out \u001b[39m=\u001b[39m model(dummy_data)\n\u001b[0;32m---> 25\u001b[0m tvm_out \u001b[39m=\u001b[39m get_tvm_output_with_vm(\n\u001b[1;32m     26\u001b[0m     onnx_model,\n\u001b[1;32m     27\u001b[0m     tvm_inputs,\n\u001b[1;32m     28\u001b[0m     freeze_params\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     29\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m     30\u001b[0m     dev\u001b[39m=\u001b[39;49mdev,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m np\u001b[39m.\u001b[39mtesting\u001b[39m.\u001b[39massert_allclose(torch_out\u001b[39m.\u001b[39mnumpy(), tvm_out, atol\u001b[39m=\u001b[39m\u001b[39m5e-7\u001b[39m)\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/tutorials/frontend/utils/onnx_utils.py:67\u001b[0m, in \u001b[0;36mget_tvm_output_with_vm\u001b[0;34m(graph_def, input_data, target, dev, opset, freeze_params, convert_config, validate_structural_equal)\u001b[0m\n\u001b[1;32m     64\u001b[0m _, shape_dict \u001b[39m=\u001b[39m get_input_data_shape_dict(graph_def, input_data)\n\u001b[1;32m     66\u001b[0m \u001b[39mwith\u001b[39;00m tvm\u001b[39m.\u001b[39mtesting\u001b[39m.\u001b[39mdisable_span_filling():\n\u001b[0;32m---> 67\u001b[0m     mod, params \u001b[39m=\u001b[39m relay\u001b[39m.\u001b[39;49mfrontend\u001b[39m.\u001b[39;49mfrom_onnx(\n\u001b[1;32m     68\u001b[0m         graph_def,\n\u001b[1;32m     69\u001b[0m         shape_dict,\n\u001b[1;32m     70\u001b[0m         opset\u001b[39m=\u001b[39;49mopset,\n\u001b[1;32m     71\u001b[0m         freeze_params\u001b[39m=\u001b[39;49mfreeze_params,\n\u001b[1;32m     72\u001b[0m         convert_config\u001b[39m=\u001b[39;49mconvert_config,\n\u001b[1;32m     73\u001b[0m     )\n\u001b[1;32m     74\u001b[0m     \u001b[39m# handle the bfloat16 so we explicitly allocate\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     \u001b[39m# bfloat16 arrays as input\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[39mfor\u001b[39;00m i, param \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(mod[\u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mparams):\n",
      "File \u001b[0;32m/media/pc/data/tmp/cache/conda/envs/tvmx/lib/python3.10/site-packages/tvm/relay/frontend/onnx.py:7194\u001b[0m, in \u001b[0;36mfrom_onnx\u001b[0;34m(model, shape, dtype, opset, freeze_params, convert_config, export_node_renamed_model_path)\u001b[0m\n\u001b[1;32m   7192\u001b[0m \u001b[39m# Use the graph proto as a scope so that ops can access other nodes if needed.\u001b[39;00m\n\u001b[1;32m   7193\u001b[0m \u001b[39mwith\u001b[39;00m g:\n\u001b[0;32m-> 7194\u001b[0m     mod, params \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49mfrom_onnx(graph, opset)\n\u001b[1;32m   7196\u001b[0m \u001b[39mif\u001b[39;00m export_node_renamed_model_path:\n\u001b[1;32m   7197\u001b[0m     export_model(export_node_renamed_model_path, graph)\n",
      "File \u001b[0;32m/media/pc/data/tmp/cache/conda/envs/tvmx/lib/python3.10/site-packages/tvm/relay/frontend/onnx.py:6813\u001b[0m, in \u001b[0;36mGraphProto.from_onnx\u001b[0;34m(self, graph, opset, get_output_expr)\u001b[0m\n\u001b[1;32m   6811\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_user_inputs_in_outermost_graph_scope()\n\u001b[1;32m   6812\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_for_unsupported_ops(graph)\n\u001b[0;32m-> 6813\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_construct_nodes(graph)\n\u001b[1;32m   6815\u001b[0m \u001b[39m# now return the outputs\u001b[39;00m\n\u001b[1;32m   6816\u001b[0m outputs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nodes[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_value_proto(i)] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m graph\u001b[39m.\u001b[39moutput]\n",
      "File \u001b[0;32m/media/pc/data/tmp/cache/conda/envs/tvmx/lib/python3.10/site-packages/tvm/relay/frontend/onnx.py:6928\u001b[0m, in \u001b[0;36mGraphProto._construct_nodes\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m   6925\u001b[0m attr[\u001b[39m\"\u001b[39m\u001b[39mtvm_custom\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m i_name\n\u001b[1;32m   6926\u001b[0m attr[\u001b[39m\"\u001b[39m\u001b[39mtvm_custom\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mnum_outputs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(node_output)\n\u001b[0;32m-> 6928\u001b[0m op \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_operator(op_name, inputs, attr, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopset)\n\u001b[1;32m   6929\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(op, _expr\u001b[39m.\u001b[39mTupleWrapper):\n\u001b[1;32m   6930\u001b[0m     outputs_num \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/media/pc/data/tmp/cache/conda/envs/tvmx/lib/python3.10/site-packages/tvm/relay/frontend/onnx.py:7052\u001b[0m, in \u001b[0;36mGraphProto._convert_operator\u001b[0;34m(self, op_name, inputs, attrs, opset)\u001b[0m\n\u001b[1;32m   7050\u001b[0m     sym \u001b[39m=\u001b[39m get_relay_op(op_name)(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mattrs)\n\u001b[1;32m   7051\u001b[0m \u001b[39melif\u001b[39;00m op_name \u001b[39min\u001b[39;00m convert_map:\n\u001b[0;32m-> 7052\u001b[0m     sym \u001b[39m=\u001b[39m convert_map[op_name](inputs, attrs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_params)\n\u001b[1;32m   7053\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   7054\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOperator \u001b[39m\u001b[39m{\u001b[39;00mop_name\u001b[39m}\u001b[39;00m\u001b[39m not implemented.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/pc/data/tmp/cache/conda/envs/tvmx/lib/python3.10/site-packages/tvm/relay/frontend/onnx.py:5040\u001b[0m, in \u001b[0;36mATen._impl_v1\u001b[0;34m(cls, inputs, attr, params)\u001b[0m\n\u001b[1;32m   5038\u001b[0m operator \u001b[39m=\u001b[39m attr\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39moperator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5039\u001b[0m \u001b[39massert\u001b[39;00m operator, \u001b[39m\"\u001b[39m\u001b[39mATen Operator not found\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 5040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_op_dispatch(operator, inputs, attr, params)\n",
      "File \u001b[0;32m/media/pc/data/tmp/cache/conda/envs/tvmx/lib/python3.10/site-packages/tvm/relay/frontend/onnx.py:4950\u001b[0m, in \u001b[0;36mATen._op_dispatch\u001b[0;34m(cls, operator, inputs, attr, params)\u001b[0m\n\u001b[1;32m   4941\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   4942\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_op_dispatch\u001b[39m(\u001b[39mcls\u001b[39m, operator, inputs, attr, params):\n\u001b[1;32m   4943\u001b[0m     op_map \u001b[39m=\u001b[39m {\n\u001b[1;32m   4944\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_size,\n\u001b[1;32m   4945\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marange\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_arange,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4948\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39membedding_bag\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_embedding_bag,\n\u001b[1;32m   4949\u001b[0m     }\n\u001b[0;32m-> 4950\u001b[0m     \u001b[39massert\u001b[39;00m operator \u001b[39min\u001b[39;00m op_map, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOperator \u001b[39m\u001b[39m{\u001b[39;00moperator\u001b[39m}\u001b[39;00m\u001b[39m is not supported.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4951\u001b[0m     \u001b[39mreturn\u001b[39;00m op_map[operator](inputs, attr, params)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Operator numel is not supported."
     ]
    }
   ],
   "source": [
    "test_aten(\"llvm\", tvm.cpu())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `index_put_slice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class IndexPutModel(torch.nn.Module):\n",
    "    def __init__(self, indices, values, accumulate):\n",
    "        super().__init__()\n",
    "        self.indices = indices\n",
    "        self.values = values\n",
    "        self.accumulate = accumulate\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.index_put(self.indices, self.values, self.accumulate)\n",
    "\n",
    "def _convert_to_onnx(model, dummy_data):\n",
    "    file_name = \"aten_model.onnx\"\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_data,\n",
    "        file_name,\n",
    "        export_params=True,\n",
    "        verbose=False,\n",
    "        opset_version=11,\n",
    "        operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK,\n",
    "    )\n",
    "    onnx_model = onnx.load(file_name)\n",
    "    return onnx_model\n",
    "\n",
    "def verify_index_put(data_shape, indices, accumulate):\n",
    "    target = \"llvm\"\n",
    "    dev = tvm.cpu()\n",
    "    dummy_data = torch.ones(data_shape)\n",
    "    tvm_inputs = [dummy_data.numpy()]\n",
    "    values = torch.rand(indices[0].size())\n",
    "    model = IndexPutModel(indices, values, accumulate)\n",
    "    onnx_model = _convert_to_onnx(model, dummy_data)\n",
    "    torch_out = model(dummy_data)\n",
    "\n",
    "    tvm_out = get_tvm_output_with_vm(onnx_model, tvm_inputs, target, dev, freeze_params=True)\n",
    "    tvm.testing.assert_allclose(torch_out.numpy(), tvm_out)\n",
    "\n",
    "shape = (3, 5)\n",
    "xidx = torch.tensor([0, 1, 2, 2])\n",
    "yidx = torch.tensor([0, 1, 3, 4])\n",
    "verify_index_put(shape, [xidx, yidx], True)\n",
    "\n",
    "shape = (3, 5, 3)\n",
    "xidx = torch.tensor([0, 1, 2, 2, 0])\n",
    "yidx = torch.tensor([0, 1, 3, 4, 0])\n",
    "zidx = torch.tensor([0, 1, 1, 2, 0])\n",
    "verify_index_put(shape, [xidx, yidx, zidx], False)\n",
    "\n",
    "def verify_index_put_slice(data_shape, value_shape, accumulate):\n",
    "    dummy_data = torch.ones(data_shape)\n",
    "    tvm_inputs = [dummy_data.numpy()]\n",
    "    indices = []\n",
    "    index_shape = [1] * len(value_shape)\n",
    "    index_shape[0] = -1\n",
    "    for _, v_shape in enumerate(value_shape):\n",
    "        indices.append(torch.arange(0, v_shape).reshape(tuple(index_shape)))\n",
    "        index_shape.pop()\n",
    "    values = torch.rand(value_shape)\n",
    "\n",
    "    model = IndexPutModel(indices, values, accumulate)\n",
    "    onnx_model = _convert_to_onnx(model, dummy_data)\n",
    "    torch_out = model(dummy_data)\n",
    "\n",
    "    target = \"llvm\"\n",
    "    dev = tvm.cpu()\n",
    "    tvm_out = get_tvm_output_with_vm(onnx_model, tvm_inputs, target, dev, freeze_params=True)\n",
    "    np.testing.assert_allclose(torch_out.numpy(), tvm_out)\n",
    "\n",
    "verify_index_put_slice((3, 3), (2, 2), False)\n",
    "verify_index_put_slice((2, 3, 4), (1, 2, 3), True)\n",
    "verify_index_put_slice((2, 3, 4, 5), (1, 2, 3, 1), False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `torchvision` 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import onnx\n",
    "\n",
    "def check_torch_conversion(model, input_size, target, dev):\n",
    "    dummy_input = torch.randn(*input_size)\n",
    "    file_name = f\"{model.__name__}.onnx\"\n",
    "    # Set verbose=True for more output\n",
    "    torch.onnx.export(model(), dummy_input, file_name, export_params=True, verbose=False)\n",
    "    onnx_model = onnx.load(file_name)\n",
    "    input_data = np.random.uniform(size=input_size).astype(\"float32\")\n",
    "    verify_with_ort_with_inputs(\n",
    "        onnx_model, [input_data], apply_softmax=True, target=target, dev=dev\n",
    "    )\n",
    "\n",
    "# def test_alexnet():\n",
    "# Torch's ONNX export does not support the adaptive pooling used by AlexNet?\n",
    "# check_torch_conversion(torchvision.models.alexnet, (1,3,224,224))\n",
    "\n",
    "# Torch's ONNX export does not support the adaptive pooling used by vgg16?\n",
    "# def test_vgg16():\n",
    "#     check_torch_conversion(torchvision.models.vgg16, (1,3,224,224))\n",
    "\n",
    "# TODO(@jroesch): Update Torch + ONNX to support this import.\n",
    "# def test_squeezenet():\n",
    "#     # Torch's ONNX export does not support the max pooling used by Squezenet\n",
    "#     check_torch_conversion(torchvision.models.squeezenet1_0, (1,3,224,224))\n",
    "\n",
    "# TODO(@jroesch): Update Torch + ONNX to support this import.\n",
    "# def test_googlenet():\n",
    "#     check_torch_conversion(torchvision.models.googlenet, (1,3,224,224))\n",
    "\n",
    "# TODO(@jroesch): Update Torch + ONNX to support this import.\n",
    "# def test_shufflenetv2():\n",
    "#     check_torch_conversion(torchvision.models.shufflenetv2, (1,3,224,224))\n",
    "\n",
    "@tvm.testing.parametrize_targets\n",
    "def test_densenet(target, dev):\n",
    "    check_torch_conversion(torchvision.models.densenet161, (1, 3, 224, 224), target, dev)\n",
    "\n",
    "\n",
    "@tvm.testing.parametrize_targets\n",
    "def test_inception(target, dev):\n",
    "    check_torch_conversion(torchvision.models.inception_v3, (1, 3, 224, 224), target, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `resnet18`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"llvm\"\n",
    "dev = tvm.cpu()\n",
    "check_torch_conversion(torchvision.models.resnet18, (1, 3, 224, 224), target, dev)\n",
    "# check_torch_conversion(torchvision.models.resnet101, (1,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
