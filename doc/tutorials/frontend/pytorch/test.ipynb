{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 前端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.ao.quantization import get_default_qat_qconfig_mapping\n",
    "from torch.ao.quantization.quantize_fx import prepare_qat_fx, convert_fx\n",
    "from tqdm import tqdm\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "class Demo(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(16, 64, 3, 1, 1, bias=False, groups=16)\n",
    "        # self.prelu = nn.PReLU(64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv(x)\n",
    "        # x = self.prelu(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/tmp/cache/conda/envs/tvmz/lib/python3.10/site-packages/torch/ao/quantization/utils.py:310: UserWarning: must run observer before calling calculate_qparams. Returning default values.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Demo()\n",
    "shape = 1, 16, 32, 32\n",
    "example_inputs = [torch.rand(*shape),]\n",
    "# script_module = torch.jit.trace(model.eval(), example_inputs)\n",
    "model_qat = torch.fx.symbolic_trace(model)\n",
    "model_qat = torch.fx.GraphModule(model_qat, model_qat.graph)\n",
    "qconfig_mapping = get_default_qat_qconfig_mapping(\"qnnpack\")\n",
    "model_prepared = prepare_qat_fx(model_qat, qconfig_mapping, example_inputs).eval()\n",
    "model_converted = convert_fx(model_prepared).eval()\n",
    "script_module = torch.jit.trace(model_converted.eval(), example_inputs).eval()\n",
    "input_infos = [(\"data\", shape),]\n",
    "default_dtype = \"float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.relay.frontend.pytorch import from_pytorch\n",
    "\n",
    "input_infos = [(\"data\", shape),]\n",
    "mod, params = from_pytorch(\n",
    "    script_module, input_infos,\n",
    "    custom_convert_map=None,\n",
    "    default_dtype='float32',\n",
    "    use_parser_friendly_name=False,\n",
    "    keep_quantized_weight=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%data: Tensor[(1, 16, 32, 32), float32] /* span=aten::quantize_per_tensor_0.data:0:0 */, %conv_weight: Tensor[(64, 1, 3, 3), float32] /* span=quantized::conv2d_relu_0:0:0 */) {\n",
      "  %0 = qnn.quantize(%data, 1f /* span=aten::quantize_per_tensor_0:0:0 */, 0 /* span=aten::quantize_per_tensor_0:0:0 */, out_dtype=\"uint8\", axis=1) /* span=aten::quantize_per_tensor_0:0:0 */;\n",
      "  %1 = nn.pad(%0, 0f /* span=quantized::conv2d_relu_0:0:0 */, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* span=quantized::conv2d_relu_0:0:0 */;\n",
      "  %2 = qnn.quantize(%conv_weight, 0.00261353f /* span=quantized::conv2d_relu_0:0:0 */, 0 /* span=quantized::conv2d_relu_0:0:0 */, out_dtype=\"int8\", axis=0) /* span=quantized::conv2d_relu_0:0:0 */;\n",
      "  %3 = qnn.conv2d(%1, %2, 0 /* span=quantized::conv2d_relu_0:0:0 */, 0 /* span=quantized::conv2d_relu_0:0:0 */, 1f /* span=quantized::conv2d_relu_0:0:0 */, 0.00261353f /* span=quantized::conv2d_relu_0:0:0 */, padding=[0, 0, 0, 0], groups=16, channels=64, kernel_size=[3, 3], out_dtype=\"int32\") /* span=quantized::conv2d_relu_0:0:0 */;\n",
      "  %4 = qnn.requantize(%3, 0.00261353f /* span=quantized::conv2d_relu_0:0:0 */, 0 /* span=quantized::conv2d_relu_0:0:0 */, 1f /* span=quantized::conv2d_relu_0:0:0 */, 0 /* span=quantized::conv2d_relu_0:0:0 */, axis=1, out_dtype=\"int32\") /* span=quantized::conv2d_relu_0:0:0 */;\n",
      "  %5 = clip(%4, a_min=0f, a_max=255f) /* span=quantized::conv2d_relu_0:0:0 */;\n",
      "  %6 = cast(%5, dtype=\"uint8\") /* span=quantized::conv2d_relu_0:0:0 */;\n",
      "  qnn.dequantize(%6, 1f /* span=aten::dequantize_0:0:0 */, 0 /* span=aten::dequantize_0:0:0 */) /* span=aten::dequantize_0:0:0 */\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(mod[\"main\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = script_module.graph.copy()\n",
    "graph_inputs = list(graph.inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[self.1 defined in (%self.1 : __torch__.torch.fx.graph_module.GraphModule, %x : Float(1, 16, 32, 32, strides=[16384, 1024, 32, 1], requires_grad=0, device=cpu) = prim::Param()\n",
       " ),\n",
       " x defined in (%self.1 : __torch__.torch.fx.graph_module.GraphModule, %x : Float(1, 16, 32, 32, strides=[16384, 1024, 32, 1], requires_grad=0, device=cpu) = prim::Param()\n",
       " )]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
