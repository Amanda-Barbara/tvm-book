{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tensorflow 前端\n",
        "\n",
        "参考: [TVM Tensorflow 前端](https://xinetzone.github.io/tvm/docs/arch/frontend/tensorflow.html)\n",
        "\n",
        "下面以 [mobilenet_v2 float_v2_1.4_224](https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.4_224.tgz) 为例，展示 Tensorflow 前端。\n",
        "\n",
        "先运行简单的测试："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-12 14:49:19.892229: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-06-12 14:49:19.940377: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-06-12 14:49:19.941288: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-12 14:49:21.295097: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "try:\n",
        "    tf1 = tf.compat.v1\n",
        "except (ImportError, AttributeError):\n",
        "    tf1 = tf\n",
        "import tvm.relay.testing.tf as tf_testing\n",
        "import tvm\n",
        "from tvm import relay\n",
        "from tvm.contrib import graph_executor\n",
        "\n",
        "\n",
        "def convert_to_list(x):\n",
        "    if not isinstance(x, list):\n",
        "        x = [x]\n",
        "    return x\n",
        "\n",
        "def run_tf_graph(sess, input_data, input_node, output_node):\n",
        "    \"\"\"执行 TensorFlow 的通用函数。\"\"\"\n",
        "    input_data = convert_to_list(input_data)\n",
        "    input_node = convert_to_list(input_node)\n",
        "    output_node = convert_to_list(output_node)\n",
        "\n",
        "    tensor = [sess.graph.get_tensor_by_name(output_name) for output_name in output_node]\n",
        "\n",
        "    input_dict = {e: input_data[i] for i, e in enumerate(input_node)}\n",
        "    if len(input_node) == 1 and input_node[0] == \"\":\n",
        "        output_data = sess.run(tensor)\n",
        "    else:\n",
        "        output_data = sess.run(tensor, input_dict)\n",
        "    return output_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/__pypackages__/3.10/lib/tvm/relay/testing/tf.py:282: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "WARNING:tensorflow:From /media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/__pypackages__/3.10/lib/tvm/relay/testing/tf.py:136: convert_variables_to_constants (from tensorflow.python.framework.convert_to_constants) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
            "WARNING:tensorflow:From /media/pc/data/tmp/cache/conda/envs/tvmz/lib/python3.10/site-packages/tensorflow/python/framework/convert_to_constants.py:952: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-12 14:49:27.250575: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2023-06-12 14:49:27.533544: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n"
          ]
        }
      ],
      "source": [
        "shape = 1, 224, 224, 3\n",
        "data = np.random.uniform(size=shape).astype(\"float32\")\n",
        "out_node = \"MobilenetV2/Predictions/Reshape_1\"\n",
        "input_name = \"input\"\n",
        "with tf.Graph().as_default():\n",
        "    graph_def = tf_testing.get_workload(\n",
        "        \"https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.4_224.tgz\",\n",
        "        \"mobilenet_v2_1.4_224_frozen.pb\",\n",
        "    )\n",
        "    # 调用实用程序将图定义导入默认 graph\n",
        "    graph_def = tf_testing.ProcessGraphDefParam(graph_def)\n",
        "    with tf1.Session() as sess:\n",
        "        # 添加 shapes 到 graph\n",
        "        graph_def = tf_testing.AddShapesToGraphDef(sess, out_node)\n",
        "        tf_output = run_tf_graph(sess, data, f\"{input_name}:0\", f\"{out_node}:0\")\n",
        "        mod, params = relay.frontend.from_tensorflow(\n",
        "            graph_def,\n",
        "            shape={\n",
        "                input_name: shape\n",
        "            }\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "desired_layouts = {\n",
        "    # 'image.resize2d': ['NCHW'],\n",
        "    'nn.conv2d': ['NCHW', 'default'],\n",
        "    'nn.max_pool2d': ['NCHW', 'default'],\n",
        "    'nn.avg_pool2d': ['NCHW', 'default'],\n",
        "}\n",
        "\n",
        "# 将布局转换为 NCHW\n",
        "# RemoveUnusedFunctions 用于清理图。\n",
        "seq = tvm.transform.Sequential([relay.transform.RemoveUnusedFunctions(),\n",
        "                                relay.transform.ConvertLayout(desired_layouts)])\n",
        "with tvm.transform.PassContext(opt_level=3):\n",
        "    mod = seq(mod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
          ]
        }
      ],
      "source": [
        "target = tvm.target.Target(\"llvm\", host=\"llvm\")\n",
        "dev = tvm.cpu(0)\n",
        "with relay.build_config(opt_level=3):\n",
        "     lib = relay.build(mod, target, params=params)\n",
        "m = graph_executor.GraphModule(lib[\"default\"](dev))\n",
        "m.set_input(**{input_name: data})\n",
        "m.run()\n",
        "tvm_output = [m.get_output(kk).numpy() for kk in range(m.get_num_outputs())]\n",
        "np.testing.assert_allclose(\n",
        "    np.squeeze(tvm_output[0]), np.squeeze(tf_output[0]), rtol=1e-5, atol=1e-5\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ImageNet 测试\n",
        "\n",
        "使用 [slim/datasets/imagenet.py](https://github.com/tensorflow/models/blob/master/research/slim/datasets/imagenet.py) 获取数据标签信息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from github import Github\n",
        "\n",
        "\n",
        "g = Github(user_agent=\"xinetzone\")\n",
        "repo = g.get_repo(\"tensorflow/models\")\n",
        "label_content = repo.get_contents(\"research/slim/datasets/imagenet_lsvrc_2015_synsets.txt\")\n",
        "imagenet_labels = label_content.decoded_content.decode().split()\n",
        "assert len(imagenet_labels) == 1000\n",
        "metadata = repo.get_contents(\"research/slim/datasets/imagenet_metadata.txt\")\n",
        "imagenet_metadata = metadata.decoded_content.decode().splitlines()\n",
        "synset_to_human = {}\n",
        "for metadata in imagenet_metadata:\n",
        "    name, value = metadata.split(\"\\t\")\n",
        "    synset_to_human[name] = value"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TensorFlow 中将背景作为标签 `0`，故而，有："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "name2id = {name: k+1 for k, name in enumerate(imagenet_labels)}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "读取数据集："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ImageNet:\n",
        "    root: str | Path # 数据根目录\n",
        "    height: int = 224\n",
        "    width: int = 224\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.root = Path(self.root)\n",
        "\n",
        "    def data_iter(self, mode=\"train\"):\n",
        "        for root in (self.root/mode).iterdir():\n",
        "            for path in root.iterdir():\n",
        "                with Image.open(path) as im:\n",
        "                    if im.mode != \"RGB\":\n",
        "                        im = im.convert(\"RGB\")\n",
        "                    img = np.array(im.resize((self.height, self.width)))\n",
        "                yield img, root.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "50000it [16:28, 50.59it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "data_dir = \"/media/pc/data/lxw/home/data/datasets/ILSVRC\"\n",
        "dataset = ImageNet(data_dir)\n",
        "\n",
        "m = graph_executor.GraphModule(lib[\"default\"](dev))\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "for k, (img, label) in tqdm(enumerate(dataset.data_iter(\"val\"))):\n",
        "    img = img/128 - 1\n",
        "    m.set_input(**{\"input\": np.expand_dims(img, 0)})\n",
        "    m.run()\n",
        "    tvm_output = m.get_output(0).numpy()\n",
        "    pred_labels.append(tvm_output.argmax())\n",
        "    true_labels.append(name2id[label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.73074"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(np.array(true_labels) == np.array(pred_labels))/len(true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
