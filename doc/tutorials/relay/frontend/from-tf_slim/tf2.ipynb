{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow2 推理\n",
    "\n",
    "下面以模型 [resnet_v2_50](http://download.tensorflow.org/models/resnet_v2_50_2017_04_14.tar.gz) 为例展示。\n",
    "\n",
    "需要克隆项目 [models](https://github.com/tensorflow/models)，然后执行如下操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 18:56:28.623811: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-13 18:56:28.672936: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-13 18:56:28.675980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-13 18:56:29.609843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/pc/data/tmp/cache/conda/envs/tvmz/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "try:\n",
    "    tf1 = tf.compat.v1\n",
    "    tf1.disable_v2_behavior()\n",
    "except (ImportError, AttributeError):\n",
    "    tf1 = tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "切换到 `models/research/slim` 目录下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tasks/models/research/slim\n"
     ]
    }
   ],
   "source": [
    "%cd /media/pc/data/lxw/ai/tasks/models/research/slim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义缓存目录："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_dir = '/tmp/checkpoints'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载权重文件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import dataset_utils\n",
    "\n",
    "url = \"http://download.tensorflow.org/models/resnet_v2_50_2017_04_14.tar.gz\"\n",
    "\n",
    "if not tf1.gfile.Exists(checkpoints_dir):\n",
    "    tf1.gfile.MakeDirs(checkpoints_dir)\n",
    "\n",
    "dataset_utils.download_and_uncompress_tarball(url, checkpoints_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 升级 TF1 为 TF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_1794279/573845400.py:16: The name tf.keras.utils.track_tf1_style_variables is deprecated. Please use tf.compat.v1.keras.utils.track_tf1_style_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from nets import resnet_v2\n",
    "from preprocessing.preprocessing_factory import get_preprocessing\n",
    "import tf_slim as slim\n",
    "\n",
    "\n",
    "class ResnetV2_50(tf.keras.layers.Layer):\n",
    "    def __init__(self, image_size, num_classes=1001, trainable=True, \n",
    "                 name=\"resnet_v2_50\", dtype=None, dynamic=False, **kwargs):\n",
    "        super().__init__(trainable, name, dtype, dynamic, **kwargs)\n",
    "        self.image_size = image_size\n",
    "        self.num_classes = num_classes\n",
    "        self.preprocessing = get_preprocessing(self.name)\n",
    "\n",
    "    @tf1.keras.utils.track_tf1_style_variables\n",
    "    def call(self, inputs):\n",
    "        processed_image = self.preprocessing(inputs, self.image_size, self.image_size)\n",
    "        processed_images  = tf.expand_dims(processed_image/256, 0)\n",
    "        \n",
    "        # Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "        with slim.arg_scope(resnet_v2.resnet_arg_scope()):\n",
    "            logits, _ = resnet_v2.resnet_v2_50(processed_images, \n",
    "                                               num_classes=self.num_classes,\n",
    "                                               global_pool=True,\n",
    "                                               is_training=self.trainable,\n",
    "                                               scope=self.name)\n",
    "        return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/pc/data/tmp/cache/conda/envs/tvmz/lib/python3.10/site-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/tmp/cache/conda/envs/tvmz/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "model = ResnetV2_50(224)\n",
    "x = tf.random.normal(shape=(224, 224, 3))\n",
    "x = tf.cast(x, tf.uint8)\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from nets import resnet_v2\n",
    "from preprocessing.preprocessing_factory import get_preprocessing\n",
    "import tf_slim as slim\n",
    "\n",
    "preprocessing = get_preprocessing(\"resnet_v2_50\")\n",
    "image_size = 224\n",
    "path = '/media/pc/data/board/arria10/lxw/data/test/cat.png' # 将要预测的图片路径\n",
    "\n",
    "with Image.open(path) as im:\n",
    "    if im.mode != \"RGB\":\n",
    "        im.convert(\"RGB\")\n",
    "    image = np.asarray(im)\n",
    "\n",
    "\n",
    "with tf1.Graph().as_default():\n",
    "    image = tf.constant(image)\n",
    "    processed_image = preprocessing(image, image_size, image_size)\n",
    "    processed_images  = tf.expand_dims(processed_image/256, 0)\n",
    "    \n",
    "    # 创建模型时，使用默认的参数范围（arg scope）来配置批归一化（batch norm）参数。\n",
    "    with slim.arg_scope(resnet_v2.resnet_arg_scope()):\n",
    "        logits, _ = resnet_v2.resnet_v2_50(processed_images, num_classes=1001,\n",
    "                                           global_pool=True,\n",
    "                                           is_training=False)\n",
    "    probabilities = tf.nn.softmax(logits)\n",
    "    \n",
    "    init_fn = slim.assign_from_checkpoint_fn(\n",
    "        f'{checkpoints_dir}/resnet_v2_50.ckpt',\n",
    "        slim.get_model_variables('resnet_v2_50'))\n",
    "    \n",
    "    with tf1.Session() as sess:\n",
    "        init_fn(sess)\n",
    "        np_processed_image, probabilities = sess.run([processed_image, probabilities])\n",
    "        probabilities = probabilities[0, 0:]\n",
    "        sorted_inds = [i[0] for i in sorted(enumerate(-probabilities), key=lambda x:x[1])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印标签信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "\n",
    "\n",
    "g = Github(user_agent=\"xinetzone\")\n",
    "repo = g.get_repo(\"tensorflow/models\")\n",
    "label_content = repo.get_contents(\"research/slim/datasets/imagenet_lsvrc_2015_synsets.txt\")\n",
    "imagenet_labels = label_content.decoded_content.decode().split()\n",
    "assert len(imagenet_labels) == 1000\n",
    "metadata = repo.get_contents(\"research/slim/datasets/imagenet_metadata.txt\")\n",
    "imagenet_metadata = metadata.decoded_content.decode().splitlines()\n",
    "synset_to_human = {}\n",
    "for metadata in imagenet_metadata:\n",
    "    name, value = metadata.split(\"\\t\")\n",
    "    synset_to_human[name] = value\n",
    "name2id = {name: k+1 for k, name in enumerate(imagenet_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 5\n",
    "for prob, sorted_ind in zip(probabilities[:topk], sorted_inds[:topk]):\n",
    "    label = synset_to_human[imagenet_labels[sorted_ind-1]]\n",
    "    print(f\"{sorted_ind-1}: {label.ljust(20)}\\t{prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
