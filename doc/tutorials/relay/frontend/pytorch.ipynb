{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 前端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.ao.quantization import get_default_qat_qconfig_mapping\n",
    "from torch.ao.quantization.quantize_fx import prepare_qat_fx, convert_fx\n",
    "from tqdm import tqdm\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "class Demo(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(16, 64, 3, 1, 1, bias=False, groups=16)\n",
    "        # self.prelu = nn.PReLU(64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv(x)\n",
    "        # x = self.prelu(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/tmp/cache/conda/envs/tvmz/lib/python3.10/site-packages/torch/ao/quantization/utils.py:310: UserWarning: must run observer before calling calculate_qparams. Returning default values.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Demo()\n",
    "shape = 1, 16, 32, 32\n",
    "example_inputs = [torch.rand(*shape),]\n",
    "# script_module = torch.jit.trace(model.eval(), example_inputs)\n",
    "model_qat = torch.fx.symbolic_trace(model)\n",
    "model_qat = torch.fx.GraphModule(model_qat, model_qat.graph)\n",
    "qconfig_mapping = get_default_qat_qconfig_mapping(\"qnnpack\")\n",
    "model_prepared = prepare_qat_fx(model_qat, qconfig_mapping, example_inputs).eval()\n",
    "model_converted = convert_fx(model_prepared).eval()\n",
    "script_module = torch.jit.trace(model_converted.eval(), example_inputs).eval()\n",
    "input_infos = [(\"data\", shape),]\n",
    "default_dtype = \"float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.relay.frontend.pytorch import from_pytorch\n",
    "\n",
    "input_infos = [(\"data\", shape),]\n",
    "mod, params = from_pytorch(\n",
    "    script_module, input_infos,\n",
    "    custom_convert_map=None,\n",
    "    default_dtype='float32',\n",
    "    use_parser_friendly_name=False,\n",
    "    keep_quantized_weight=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = script_module.graph.copy()\n",
    "graph_inputs = list(graph.inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/tutorials/relay/frontend/draft/resnet18_cifar10_relu_qat\"\n",
    "script_module = torch.jit.load(f\"{ROOT}/weight/resnet18_cifar10_relu_qat.h5\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_infos = [(\"data\", (1, 3, 224, 224)),]\n",
    "mod, params = from_pytorch(\n",
    "    script_module, input_infos,\n",
    "    custom_convert_map=None,\n",
    "    default_dtype='float32',\n",
    "    use_parser_friendly_name=False,\n",
    "    keep_quantized_weight=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm.relay.frontend import qnn_torch\n",
    "from tvm.relay.frontend.pytorch import (\n",
    "    _run_jit_passes,\n",
    "    Prelude, PyTorchOpConverter,\n",
    "    get_all_op_names,\n",
    "    _get_relay_input_vars,\n",
    "    _debug_rename,\n",
    "    convert_params,\n",
    "    _get_output_name,\n",
    "    get_attr_chains,\n",
    "    _getattr_full_name,\n",
    "    _get_users,\n",
    "    getattr_attr_name,\n",
    "    _get_tensor_and_var\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_parser_friendly_name = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tvm.IRModule()\n",
    "prelude = Prelude(mod)\n",
    "enable_lower_all_tuples = True\n",
    "\n",
    "converter = PyTorchOpConverter(prelude, default_dtype, use_parser_friendly_name)\n",
    "graph = script_module.graph.copy()\n",
    "graph_inputs = list(graph.inputs())\n",
    "_run_jit_passes(graph, enable_lower_all_tuples)\n",
    "op_names = get_all_op_names(graph)\n",
    "converter.report_missing_conversion(op_names)\n",
    "is_module = isinstance(script_module, torch.jit.ScriptModule)\n",
    "params = script_module.state_dict() if is_module else {}\n",
    "outputs = _get_relay_input_vars(\n",
    "    graph, input_infos, prelude, default_dtype=default_dtype, is_module=is_module\n",
    ")\n",
    "source_map = _debug_rename(graph, use_parser_friendly_name)\n",
    "param_vars, tensors, packed_param_map, param_debug_name_map = convert_params(\n",
    "    graph, params, source_map, use_parser_friendly_name\n",
    ")\n",
    "tvm_params = {k: tvm.nd.array(v) for k, v in tensors.items()}\n",
    "outputs.update(param_vars)\n",
    "quantized_ops = set([\"aten::quantize_per_tensor\", \"quantized::linear_dynamic\"])\n",
    "if len(quantized_ops.intersection(set(op_names))) > 0:\n",
    "    weight_quant_params = qnn_torch.get_weight_quant_params(\n",
    "        script_module, packed_param_map.values()\n",
    "    )\n",
    "    qnn_torch.inline_input_quant_params_for_fx(graph, tensors, param_debug_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = params\n",
    "# getattr_nodes = graph.findAllNodes(\"prim::GetAttr\", recurse=True)\n",
    "# params = {}\n",
    "# param_tensors = {}\n",
    "# packed_param_map = {}\n",
    "# param_debug_name_map = {}\n",
    "# vars_by_name = {}\n",
    "# seen = set()\n",
    "# attr_name_sep = \"_\" if use_parser_friendly_name else \".\"\n",
    "\n",
    "# for node in getattr_nodes:\n",
    "#     if _get_output_name(node) in seen:\n",
    "#         continue\n",
    "\n",
    "#     for getattrs in get_attr_chains(node):\n",
    "#         seen.update(map(_get_output_name, getattrs))\n",
    "\n",
    "#         full_attr = _getattr_full_name(getattrs, attr_name_sep)\n",
    "#         full_attr_node_name = _get_output_name(getattrs[-1])\n",
    "#         print(full_attr, full_attr_node_name)\n",
    "#         # set variable name by concatenating first consumer's name with full attribute\n",
    "#         # e.g. \"aten::batch_norm_5.running_mean\"\n",
    "#         var_name = attr_name_sep.join(\n",
    "#             [source_map[_get_users(getattrs[-1])[0]], full_attr.split(attr_name_sep)[-1]]\n",
    "#         )\n",
    "\n",
    "#         if full_attr.endswith(\"_packed_params\"):  # for quantized models\n",
    "#             packed_param_map[full_attr_node_name] = full_attr\n",
    "#         elif full_attr in state_dict:\n",
    "#             if var_name in vars_by_name:\n",
    "#                 var = vars_by_name[var_name]\n",
    "#             else:\n",
    "#                 torch_tensor = state_dict[full_attr]\n",
    "#                 tensor, var = _get_tensor_and_var(torch_tensor, var_name)\n",
    "#                 param_tensors[var_name] = tensor\n",
    "#                 # for quantized parameters to be correctly located\n",
    "#                 param_debug_name_map[full_attr_node_name] = var_name\n",
    "#                 vars_by_name[var_name] = var\n",
    "#             params[full_attr_node_name] = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_attr_name(current):\n",
    "    current_attr = getattr_attr_name(current)\n",
    "    inputs = list(current.inputs())\n",
    "    # logging.debug(f\"current_attr: {current_attr}\")\n",
    "    if len(inputs) == 1:\n",
    "        # logging.debug(f\"get_full_attr_name(inputs[0].node()): {inputs[0].node()}\")\n",
    "        if inputs[0].node().kind() == \"prim::GetAttr\":\n",
    "            return get_full_attr_name(inputs[0].node()) + \".\" + current_attr\n",
    "        elif inputs[0].node().kind() == \"prim::Param\":\n",
    "            return current_attr + \".1\"\n",
    "    return current_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in graph.findAllNodes(\"prim::GetAttr\", recurse=True):\n",
    "    out_name = node.output().debugName()\n",
    "    if \"_scale\" in out_name or \"_zero_point\" in out_name:\n",
    "        full_attr = param_debug_name_map[get_full_attr_name(node)]\n",
    "        assert full_attr in params, f\"{full_attr} not found in param dict.\"\n",
    "        param_np = params[full_attr].asnumpy()\n",
    "        new_const_node = graph.create(\"prim::Constant\")\n",
    "        new_const_node.insertBefore(node)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = node\n",
    "getattr_attr_name(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = node\n",
    "current_attr = getattr_attr_name(current)\n",
    "inputs = list(current.inputs())\n",
    "input_node = inputs[0].node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_node.kind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for getattrs in get_attr_chains(input_node):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_full_attr_name(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.output().debugName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attr = param_debug_name_map[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_map, op_type_dict = {}, {}\n",
    "prim_with_blocks = [\"prim::If\", \"prim::Loop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in graph.nodes():\n",
    "    if node.outputsSize() == 0:\n",
    "        continue\n",
    "    if node.kind() in prim_with_blocks:\n",
    "        for block in node.blocks():\n",
    "            _traverse_graph(block.nodes())\n",
    "    _rename_outputs(node, source_map, op_type_dict, use_parser_friendly_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.outputsSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
